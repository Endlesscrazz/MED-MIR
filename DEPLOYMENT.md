# Med-MIR Deployment Guide

This guide reflects the **current production architecture**:
- Frontend app on Vercel
- Data/model assets on Hugging Face Datasets (static file hosting)

---

## 1) Current Production Endpoints

- Web app: `https://med-mir.vercel.app/`
- Asset base URL:  
  `https://huggingface.co/datasets/ShreyasP07/med-mir-demo-bundle/resolve/221b2c99ef7e858bf95a4b27d7261d97fab1d1db/output`

---

## 2) Architecture at Deploy Time

## Frontend (Vercel)
- Hosts Next.js static app (`web/`)
- Serves routes:
  - `/`
  - `/metrics`
  - `/hard-cases`
  - `/benchmark`

## Static assets (Hugging Face Datasets)
- Stores heavy artifacts generated by Python pipeline:
  - `embeddings.bin`
  - `metadata.json`
  - `fallback_results.json`
  - `nearest_neighbors.json`
  - `index_info.json`
  - `metrics.json`
  - `hard_cases.json`
  - `images/*.webp`
  - `model/*` (quantized ONNX + tokenizer files)

The web app reads assets via `NEXT_PUBLIC_DATA_URL`.

---

## 3) Generate Fresh Artifacts

From project root:

```bash
# 1) Process images
python3 python/process_images.py \
  --input_dir python/data/nih/images \
  --output_dir python/output/images \
  --max_dim 256 --quality 85 --workers 4

# 2) Generate index files
med_mir/bin/python python/generate_index.py \
  --images_dir python/output/images \
  --nih_labels python/data/nih/labels.csv \
  --output_dir python/output \
  --device cpu

# 3) Export + quantize ONNX text/vision encoders
med_mir/bin/python python/export_onnx.py --output_dir python/output/model

# 4) Evaluate retrieval
med_mir/bin/python python/evaluate.py \
  --embeddings python/output/embeddings.bin \
  --metadata python/output/metadata.json \
  --output_dir python/output \
  --device cpu
```

Optional benchmark refresh:

```bash
med_mir/bin/python python/benchmark_quantization.py \
  --model_dir python/output/model \
  --images_dir python/output/images \
  --output_json python/output/quantization_benchmark.json \
  --output_md python/output/quantization_benchmark.md
```

---

## 4) Upload Assets to Hugging Face Datasets

Upload the contents of `python/output/` so your asset URL contains:

```text
output/
  embeddings.bin
  metadata.json
  fallback_results.json
  nearest_neighbors.json
  index_info.json
  metrics.json
  hard_cases.json
  images/
  model/
```

Important:
- Keep file names stable (frontend expects exact names).
- Keep `model/text_encoder_quantized.onnx` and `model/vision_encoder_quantized.onnx` present.

---

## 5) Configure Vercel

In Vercel project settings, set:

```env
NEXT_PUBLIC_SITE_URL=https://med-mir.vercel.app
NEXT_PUBLIC_DATA_URL=https://huggingface.co/datasets/ShreyasP07/med-mir-demo-bundle/resolve/221b2c99ef7e858bf95a4b27d7261d97fab1d1db/output
```

Build settings:
- Root directory: `web`
- Build command: default (`next build`)
- Output mode is already static in `web/next.config.js` (`output: 'export'`)

---

## 6) Deploy Frontend

## Option A: GitHub Integration (recommended)
1. Push code to GitHub.
2. Import repo in Vercel.
3. Set root directory to `web`.
4. Add env vars above.
5. Deploy.

## Option B: Vercel CLI
```bash
cd web
npm i -g vercel
vercel login
vercel --prod
```

---

## 7) Post-Deploy Verification

1. Open app URL.
2. Run fallback query (`pneumonia`) and verify `Cached`.
3. Run novel text query and verify `AI Inference`.
4. Upload image and verify result list appears.
5. Open `/metrics` and `/hard-cases`.
6. Open `/benchmark` and run benchmark once.
7. Check network tab:
   - assets fetched from `NEXT_PUBLIC_DATA_URL`
   - no 404 on model files or embeddings.

---

## 8) Troubleshooting

## Models or metadata fail to load
- Verify `NEXT_PUBLIC_DATA_URL` is correct and publicly accessible.
- Check exact filenames and folder structure under asset URL.

## CORS issues
- Ensure asset host allows browser fetch from your Vercel origin.

## Very slow first query
- First model download/compile is expected.
- Use fallback queries for instant demo path.
- Subsequent runs are faster due to browser cache.

## Build works locally but not on Vercel
- Re-check env vars in Vercel dashboard.
- Ensure no stale artifacts are referenced in docs/config.

---

## 9) Cost Profile

| Service | Role | Cost Target |
|---|---|---|
| Vercel (Hobby) | Frontend hosting | $0 |
| Hugging Face Datasets | Static artifact hosting | $0 (within free limits) |

This keeps deployment near zero while avoiding GPU backend costs.

